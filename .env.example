# ==============================================
# OpenAkita 配置文件
# 复制此文件为 .env 并填写你的配置
# cp .env.example .env
# ==============================================

# ========== Anthropic API (主要) ==========
ANTHROPIC_API_KEY=sk-your-api-key-here
ANTHROPIC_BASE_URL=https://api.anthropic.com

# 模型配置
DEFAULT_MODEL=claude-opus-4-5-20251101-thinking
MAX_TOKENS=8192

# ========== 备用 LLM 端点 (可选，按优先级排序) ==========
# 注意：推荐使用 data/llm_endpoints.json 进行多端点配置
# 以下环境变量被 llm_endpoints.json 中的 api_key_env 字段引用

# 备用 1: Kimi (月之暗面 Moonshot AI)
# 申请地址: https://platform.moonshot.cn/
KIMI_API_KEY=
KIMI_BASE_URL=https://api.moonshot.cn/v1
KIMI_MODEL=kimi-k2.5

# 备用 2: DashScope (阿里云通义)
# 申请地址: https://dashscope.console.aliyun.com/
DASHSCOPE_API_KEY=
DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
DASHSCOPE_MODEL=qwen3-max

# 备用 3: MiniMax
# 申请地址: https://www.minimaxi.com/
MINIMAX_API_KEY=
MINIMAX_BASE_URL=https://api.minimaxi.com/anthropic
MINIMAX_MODEL=MiniMax-M2.1

# 备用 4: DeepSeek
# 申请地址: https://platform.deepseek.com/
DEEPSEEK_API_KEY=

# 备用 5: OpenRouter (聚合多家模型)
# 申请地址: https://openrouter.ai/
OPENROUTER_API_KEY=

# 备用 6: SiliconFlow (开源模型)
# 申请地址: https://siliconflow.cn/
SILICONFLOW_API_KEY=

# ========== LLM 端点配置文件路径 ==========
# 可自定义 llm_endpoints.json 位置，默认: data/llm_endpoints.json
# LLM_ENDPOINTS_CONFIG=data/llm_endpoints.json

# ========== Agent 配置 ==========
AGENT_NAME=OpenAkita
MAX_ITERATIONS=300
AUTO_CONFIRM=false

# 数据库路径
DATABASE_PATH=data/agent.db

# 日志级别 (DEBUG/INFO/WARNING/ERROR)
LOG_LEVEL=INFO

# ========== 网络代理配置 ==========
# 用于 LLM API 请求的代理（中国大陆用户推荐配置）
# HTTP_PROXY=http://127.0.0.1:7890
# HTTPS_PROXY=http://127.0.0.1:7890
# ALL_PROXY=http://127.0.0.1:7890

# 强制使用 IPv4（解决某些 VPN 的 IPv6 兼容性问题）
# FORCE_IPV4=false

# ========== 工具并行执行 ==========
# 单轮模型返回多个工具调用时，允许并行执行以提高吞吐（默认 1=串行）。
# 注意：浏览器/桌面/MCP 等状态型工具仍会互斥；并行更适用于多个独立的 I/O 工具调用。
# TOOL_MAX_PARALLEL=1

# ========== 语音识别 ==========
# Whisper 模型选择: tiny/base/small/medium/large
# tiny: 最快但准确率较低
# base: 平衡速度和准确率 (推荐)
# medium: 较高准确率
# large: 最高准确率但较慢
WHISPER_MODEL=base

# ========== GitHub Token ==========
# 用于搜索和下载技能
# 申请地址: https://github.com/settings/tokens
GITHUB_TOKEN=

# ========== IM 通道配置 ==========

# --- Telegram ---
TELEGRAM_ENABLED=false
TELEGRAM_BOT_TOKEN=your-telegram-bot-token
# Telegram 代理地址（中国大陆必须配置）
# 支持 HTTP/HTTPS/SOCKS5 代理
# 示例: http://127.0.0.1:7890 或 socks5://127.0.0.1:1080
TELEGRAM_PROXY=

# --- 飞书 ---
# 需要额外安装: pip install openakita[feishu]
FEISHU_ENABLED=false
FEISHU_APP_ID=
FEISHU_APP_SECRET=

# --- 企业微信 ---
WEWORK_ENABLED=false
WEWORK_CORP_ID=
WEWORK_AGENT_ID=
WEWORK_SECRET=

# --- 钉钉 ---
DINGTALK_ENABLED=false
DINGTALK_APP_KEY=
DINGTALK_APP_SECRET=

# --- QQ (OneBot 协议) ---
# 需要先部署 OneBot 实现 (如 NapCat, go-cqhttp)
QQ_ENABLED=false
QQ_ONEBOT_URL=ws://127.0.0.1:8080

# ========== 记忆系统配置 ==========

# Embedding 模型 (用于向量搜索)
# 默认: shibing624/text2vec-base-chinese (中文优化，约100MB)
# 可选: sentence-transformers/all-MiniLM-L6-v2 (英文，约90MB)
# 可选: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (多语言)
EMBEDDING_MODEL=shibing624/text2vec-base-chinese

# Embedding 设备 (cpu 或 cuda)
# 如果有 NVIDIA GPU，设为 cuda 可加速
EMBEDDING_DEVICE=cpu

# 历史对话保留天数
MEMORY_HISTORY_DAYS=30

# 历史对话最大文件数
MEMORY_MAX_HISTORY_FILES=1000

# 历史对话最大占用空间 (MB)
MEMORY_MAX_HISTORY_SIZE_MB=500

# ========== 调度器配置 ==========

# 是否启用定时任务调度器
# SCHEDULER_ENABLED=true

# 调度器时区
# SCHEDULER_TIMEZONE=Asia/Shanghai

# 最大并发任务数
# SCHEDULER_MAX_CONCURRENT=5

# 定时任务执行超时时间（秒）
# SCHEDULER_TASK_TIMEOUT=600

# ========== 会话配置 ==========

# 会话超时时间（分钟）
# SESSION_TIMEOUT_MINUTES=30

# 会话最大历史消息数
# SESSION_MAX_HISTORY=50

# ========== 多 Agent 协同配置 ==========

# 是否启用多 Agent 协同模式
# 启用后，系统将使用 MasterAgent + Worker 架构
ORCHESTRATION_ENABLED=false

# ZMQ 总线地址 (Master 和 Worker 通信)
ORCHESTRATION_BUS_ADDRESS=tcp://127.0.0.1:5555

# ZMQ 广播地址 (事件广播)
ORCHESTRATION_PUB_ADDRESS=tcp://127.0.0.1:5556

# Worker 数量配置
ORCHESTRATION_MIN_WORKERS=1
ORCHESTRATION_MAX_WORKERS=5

# 心跳间隔 (秒)
ORCHESTRATION_HEARTBEAT_INTERVAL=5

# 健康检查间隔 (秒)
ORCHESTRATION_HEALTH_CHECK_INTERVAL=10
